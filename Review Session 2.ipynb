{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5c017d9-e796-4255-a2ff-df5491f323fb",
   "metadata": {},
   "source": [
    "# DSCI 100 Review Session 2 Worksheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c9c2b5-37f4-4c81-8e54-d28f846aa4e9",
   "metadata": {},
   "source": [
    ">## Author: Omer Tahir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282ddca0-4e95-4025-8dce-27349ec92db8",
   "metadata": {},
   "source": [
    "### Loading relevant packages for notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad3df9a3-29d1-442d-9d31-22908ce0be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "options(repr.matrix.max.rows = 6) #limits output of dataframes to 6 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939460dd-ef46-4dde-aefe-23bcce879df9",
   "metadata": {},
   "source": [
    "## Chapter 5: Collaboration with version control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce3c6d3-dd6c-47b6-ab34-a85115aeec5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.0 What is version control?\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a8dba1-61de-44ac-9663-dbfd0d07fd09",
   "metadata": {},
   "source": [
    "In order to version control a project, you generally need two things: \n",
    " 1) Version Control system\n",
    " 2) Repository Hosting service\n",
    "\n",
    "**Version Control:** \n",
    "* The version control system is the software that is responsible for tracking changes, sharing changes you make with others, obtaining changes others have made, and resolving conflicting edits. \n",
    "* E.g. Git, Mercurial, Subversion\n",
    "\n",
    "**Repository Hosting Service:** \n",
    "* Responsible for storing a copy of the version controlled project online (a repository), where you and your collaborators can access it remotely, discuss issues and bugs, and distribute your final product. \n",
    "* E.g. GitHub, GitLab, BitBucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04124a57-e0fa-46a5-8364-b37482597813",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.1 GitHub repository hosting service\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5733476d-380f-472a-9138-e38d9b09f6c1",
   "metadata": {},
   "source": [
    "**Cloning a repository:**\n",
    "* defined as copying/downloading the entire contents (files, project history, and location of the remote repository) of a remote GitHub.com repository to a computer (e.g., your workspace on a JupyterHub, or your laptop).\n",
    "\n",
    "**Git has a distinct step of ADDING files to the STAGING AREA because:**\n",
    "* Not all changes we make (i.e., files we create or edit) are ones that we want to push to our remote GitHub repository.\n",
    "* It allows us to edit multiple files at once, but associate particular commit messages with particular files (so that the commit messages can more specifically reflect the changes that were made).\n",
    "\n",
    "**Commit:**\n",
    "* commit messages are required, and what is in the message is important! The most useful messages describe what the change to the file(s) was about so that you can easily and effectively review the project's history!\n",
    "* When we commit our changes to Git, the snapshot of changes, the commit message, the time and date stamp and the user who committed the changes are all saved to the Git history on the LOCAL computer.\n",
    "\n",
    "**Pushing:**\n",
    "* Pushing with Git is the act of sending changes that were committed to Git to a remote repository, for example, on GitHub.com.\n",
    "* You should push your work to GitHub anytime you want to share your work with others, or when you are done a work session and want to back up your work.\n",
    "\n",
    "**Pulling:**\n",
    "* Pulling with Git is the act of collecting changes that exists in a remote repository, for example, on GitHub.com, that do not yet exist on the local computer you are working on (i.e., your workspace on the JupyterHub or your laptop)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378104a8-c7a5-4170-a43f-f2a7a5d1dfb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.2 Advantages of Version Control\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7688f59-6d6d-485a-b752-da0708e0b0ba",
   "metadata": {},
   "source": [
    "1) Version control tracks changes to the files in the analysis (code, writing, data, etc) over the lifespan of the project, including when the changes were made and who made them. This provides the means both to view earlier versions of the project and to revert changes.  \n",
    "2) Version control also facilitates collaboration via tools to share edits with others and resolve conflicting edits. Even if you’re working on a project alone it helps you keep track of what you’ve done, when you did it, and what you’re planning to do next.  \n",
    "3) Version control tools usually include a remote/cloud repository hosting service that can act as a backup of your local files (i.e., the files on your computer).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae30f9c-6772-4b24-a1b7-79d07754b361",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.3 Your workflow on JupyterHub should look like this\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59842375-f10e-4cb0-b20f-52034b81db71",
   "metadata": {},
   "source": [
    "1) You edit, create, and delete files in your cloned repository on JupyterHub.  \n",
    "2) Once you want a record of the current version, you specify which files to “add” to Git’s staging area. You can think of files in the staging area as those modified files for which you want a snapshot.  \n",
    "3) You commit those flagged files to your repository, and include a helpful commit message to tell your collaborators about the changes you made. Note: here you are only committing to your cloned repository stored on JupyterHub. The repository on GitHub has not changed, and your collaborators cannot see your work yet.  \n",
    "4) Go back to step 1. and keep working!  \n",
    "5) When you want to store your commits (that only exist in your cloned repository right now) on the cloud where they can be shared with your collaborators, you push them back to the hosted repository on GitHub.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef81cb6-97a5-42e7-b2d0-83c569634ec5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.4 GitHub Issues\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27633d07-3ba4-40cc-ad0d-82e6e9a219b7",
   "metadata": {},
   "source": [
    "* GitHub issues are an alternative written communication medium to email and messaging apps, and were designed specifically to facilitate project-specific communication.\n",
    "* Issues are opened from the “Issues” tab on the project’s GitHub page, and they persist there even after the conversation is over and the issue is closed (in contrast to email, issues are not usually deleted).\n",
    "* One issue thread is usually created per topic, and they are easily searchable using GitHub’s search tools.\n",
    "* All issues are accessible to all project collaborators, so no one is left out of the conversation.\n",
    "* Finally, issues can be setup so that team members get email notifications when a new issue is created or a new post is made in an issue thread."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a75bb9d-4d20-4c78-81c5-26aab73b5899",
   "metadata": {},
   "source": [
    "## Chapter 6: Classification I (Training and Predicting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20261f9-6f4d-4a41-9af4-48f96e692307",
   "metadata": {},
   "source": [
    "### 6.0 Important packages for chapter 6\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed9257b-1929-4a1e-99aa-8cb616f55d1f",
   "metadata": {},
   "source": [
    "* `forcats`\n",
    "    * forcats PACKAGE enables us to easily manipulate factors in R.\n",
    "    * factors are a special categorical type of variable in R that are often used for class label data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a473a02-666c-4ffd-806d-38a4726d0162",
   "metadata": {},
   "source": [
    "* `tidymodels`\n",
    "    * K-nearest neighbour algorithm is implemented in the parsnip PACKAGE included in the tidymodels package collection.\n",
    "    * The tidymodels package collection also provides the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9f4d5e-54f8-44c0-9e74-ebf1d77fc7e2",
   "metadata": {},
   "source": [
    "* `parnship`   \n",
    "    * Part of the `tidyverse` metapackage. (if you load tidyverse you do not need to load this package)\n",
    "    * The K-nearest neighbour algorithm is implemented in the \"parsnip\" package included in the tidymodels package collection, along with many other models.\n",
    "    * The tidymodels collection provides tools to help make and use models, such as classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c6cd5-1a10-4f4c-ad1d-7cb45550cb78",
   "metadata": {},
   "source": [
    "### 6.1 Classification and Training Sets\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ff1ff8-91c4-4ef6-b95a-1d45f386b534",
   "metadata": {},
   "source": [
    "* Classification is predicting a categorical class (sometimes called a label) for an observation given its other quantitative variables (sometimes called features). \n",
    "* Generally, a classifier assigns an observation (e.g. a new patient) to a class (e.g. diseased or healthy) on the basis of how similar it is to other observations for which we know the class (e.g. previous patients with known diseases and symptoms).\n",
    "* These observations with known classes that we use as a basis for prediction are called a training set.\n",
    "* We call them a “training set” because we use these observations to train, or teach, our classifier so that we can use it to make predictions on new data that we have not seen previously.\n",
    "\n",
    "> **Training Data/Set:** It is a collection of observations for which we know the true classes. It can be used to explore and build our classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d035d1dd-ee0c-4a52-b2f6-8678a0610b76",
   "metadata": {},
   "source": [
    "### 6.2 Common functions we may use in this chapter\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf4c570-4c3c-4e95-9f66-7c940c4c3685",
   "metadata": {},
   "source": [
    "* `glimpse(df)`\n",
    "    * This function can make it easier to inspect the data when we have a lot of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c255d35-e4d7-4a8e-a297-1c881ae16a28",
   "metadata": {},
   "source": [
    "* `factor(col_name, levels = c(..., ..., ...))`\n",
    "    * is used to encode a vector as a factor; it allows you to specify the values, and whether they are ordered or not.\n",
    "    * the first argument is the column you want to convert.\n",
    "    * the second argument are the values/categories/levels that are ordered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb67fd-001a-4784-ab95-2fa61cd847fe",
   "metadata": {},
   "source": [
    "* `add_row(df, col_name_1 = ..., col_name_2 = ..., ..., col_name_n = ...)`\n",
    "    * creates and adds a row/observation to the df\n",
    "    * specify the name and respective values of each column of the df in argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ace9944-4ef7-425c-ba4b-43066bf14355",
   "metadata": {},
   "source": [
    "* `as.factor()`\n",
    "    * simply coerces an existing vector to a factor, if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e7989-63b9-42d9-9db5-e0e2cc5b70d1",
   "metadata": {},
   "source": [
    "* `as_factor()`\n",
    "    * converts the column/variable into a statistical categorical variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b6bcd8-a077-4361-a0ad-d3cb12f892de",
   "metadata": {},
   "source": [
    "* `levels()`\n",
    "    * Factors have what are called “levels”, which you can think of as categories\n",
    "    * This function return the name of each category in that column.\n",
    "    * levels() function requires a vector as its argument. (Note: you might have to use `pull()` when operating on a dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e47c5d-bf7b-48eb-9217-c75b67e1455d",
   "metadata": {},
   "source": [
    "* `dist()`\n",
    "    * finds the euclidean distance between the specified observations of the dataframe.\n",
    "    * this is used with the `slice()` function to first obtain the rows and then the result is piped into `dist()`\n",
    "    * If there are more than 2 rows, the result is a matrix showing the distance between each row. pipe the result into as.matrix() to get the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b6bdf4-060c-46a9-87cd-3592161bf296",
   "metadata": {},
   "source": [
    "### 6.3 K-Nearest Neighbours Algorithm\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a78374-2ba2-463f-8ffa-098cd4963f16",
   "metadata": {},
   "source": [
    "In order to classify a new observation using a K-nearest neighbour classifier, we have to:\n",
    "\n",
    "1) Compute the distance between the new observation and each observation in the training set  \n",
    "2) Sort the data table in ascending order according to the distances  \n",
    "3) Choose the top K rows of the sorted table  \n",
    "4) Classify the new observation based on a majority vote of the neighbour classes  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07f035-4031-4ebf-bec9-07af58e5d397",
   "metadata": {},
   "source": [
    "#### **<u>Example Code:</u>**\n",
    "\n",
    "```\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 5) |>  #(1)\n",
    "        \tset_engine(\"kknn\") |>                                            #(2)\n",
    "        \tset_mode(\"classification\")                                       #(3)\n",
    "\n",
    "knn_fit <- fit(knn_spec, target_variable ~ predictor_variables, df)          #(4)\n",
    "\n",
    "new_obs <- tibble(Permimeter = 0, Concavity = 3.5)                           #(5)\n",
    "predict(knn_fit, new_obs)                                                    #(6)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d056f171-7ae5-4156-b331-98fe8964f30d",
   "metadata": {},
   "source": [
    "1) We create a model specification for K-nearest neighbours classification by calling the `nearest_neighbor()` function.  \n",
    "   Here we specify that we want to use K=5 neighbours.  \n",
    "   The `weight_func` argument controls how neighbours vote when classifying a new observation  \n",
    "   By setting it to `\"rectangular\"`, it measures the straight-line distance.\n",
    "   Each of the K nearest neighbours gets exactly 1 vote as described above.\n",
    "\n",
    "2) The `set_engine()` trains the model with a particular computational engine which needs to be specified in its argument.  \n",
    "   In this case, we specify the `\"kknn\"` engine\n",
    "\n",
    "3) The `setmode()` specifies what type of problem this is in its argument  \n",
    "   In this case, it's a `\"classification\"` problem.  \n",
    "\n",
    "4) In order to fit the model on the breast cancer data, we need to pass the model specification as the 1st argument.  \n",
    "   Specify the variables we need to use to make the prediction and what variable to use as the target in the 2nd argument. (Note: if you want to use all the other variables/columns to predict, then type `target_variable ~ .` )  \n",
    "   The data frame being used as the 3rd argument.  \n",
    "   The fit object lists the function that trains the model as well as the “best” settings for the number of neighbours and weight function  \n",
    "\n",
    "5) `new_obs <- tibble(x_col = ..., y_col = ...)` creates a new observation with the x and y values.\n",
    "\n",
    "6) prediction is made on the new observation using the fitted model and the new observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4696c1-5d51-4d6f-9848-24777d84774b",
   "metadata": {},
   "source": [
    "#### 6.3.1 Common problems using K-NN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf96f4f-835b-4b2d-b83c-b38cfae79ab6",
   "metadata": {},
   "source": [
    "1) **Varying scales of each variable**  \n",
    "When using K-nearest neighbour classification, the scale of each variable matters since large scale variables can have a greater (unwanted) affects.\n",
    "\n",
    "2) **Class Imbalance**  \n",
    "Another potential issue in a data set for a classifier is class imbalance, i.e., when one label is much more common than another.  \n",
    "If there are many more data points with one label overall, the algorithm is more likely to pick that label in general \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d891f-89f4-4180-b335-4ad8b24bbc1a",
   "metadata": {},
   "source": [
    "#### 6.3.2 Solution to these problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103e78d6-7ed4-4dd4-8521-a3bd49b42cb7",
   "metadata": {},
   "source": [
    "1) **Scaling and Centering**  \n",
    "When all variables in a data set have a mean (center) of 0 and a standard deviation (scale) of 1, we say that the data have been standardized.  \n",
    "As a rule of thumb, standardizing your data should be a part of the preprocessing you do before any predictive modelling / analysis.\n",
    "\n",
    "2) **Balancing**  \n",
    "Rebalance the data by oversampling the rare class.  \n",
    "We replicate rare observations multiple times in our data set to give them more voting power in the K-nearest neighbour algorithm.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aadbbe9-31a5-4189-ad2d-5c8c15425373",
   "metadata": {},
   "source": [
    "#### 6.3.3 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a18ec27-7b9f-427b-b9e3-c1e8476527fb",
   "metadata": {},
   "source": [
    "> **Note:** \n",
    ">* Scaling & Centering and Balancing are part of preprocessing the data\n",
    ">* In the `tidymodels` framework, data preprocessing is done by using a Recipe.\n",
    ">* `prep()` and `bake()` are used in conjunction with `recipe()` to preprocess data (e.g. centering and scaling data). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0617477-a2e6-4ac1-9d97-9ace030e59ce",
   "metadata": {},
   "source": [
    "**Explanation of the `prep()`, `bake()` workflow:**\n",
    "- `prep()` calculates the standard deviations and means required to scale and center the data. If you run the recipe before `prep()`, it just mentions the pre-processing steps it has to take.\n",
    "- `bake()` applies the results of `prep()` on to the data. \n",
    "- You might be wondering, \"why are these two separate functions, then?\". Well, you might want to calculate the standard deviations and means for one data set and use those numbers to scale a DIFFERENT data set.\n",
    "- For example, you might want to find the standard deviations for the training data set and use that to scale the testing data set. \n",
    "- This is because training our model or even standardizing our data based on the test data jeopardizes the validity of the test data and violates the golden rule of machine learning: never use any part of the test data to help make your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c457a59b-f4e3-464f-9dfb-cfa40accceb4",
   "metadata": {},
   "source": [
    "#### 6.3.4 Scaling and Centering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a064cf4-b5b7-4281-8873-0e8424120573",
   "metadata": {},
   "source": [
    "* When all variables in a data set have a mean (center) of 0 and a standard deviation (scale) of 1, we say that the data have been standardized.\n",
    "* As a rule of thumb, standardizing your data should be a part of the preprocessing you do before any predictive modelling / analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274bf36b-c3b6-4a69-bfdf-06c0dc33e524",
   "metadata": {},
   "source": [
    "##### **<u>Example Code:</u>**\n",
    "\n",
    "```\n",
    "udf_recipe <- recipe(target_col ~ ., df) |>    #(1)\n",
    "  step_scale(all_predictors()) |>              #(2)\n",
    "  step_center(all_predictors()) |>             #(3)\n",
    "  prep()                                       #(4)\n",
    "\n",
    "scaled_df <- bake(recipe, df)                  #(5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419d720a-6397-400b-a158-a9fd0b890a97",
   "metadata": {},
   "source": [
    "1) `recipe()` creates a Recipe for Preprocessing Data. Here we specify the target column/variable, and all other variables are predictors. (udf stands for unscaled dataframe)\n",
    "\n",
    "2) `step_scale()` scales numeric data. `all_predictors()` applies it to all the predictor variables/columns.\n",
    "\n",
    "3) `step_center()` centers numeric data.\n",
    "\n",
    "4) `prep()` function finalizes the recipe by using the data to compute anything necessary to run the recipe (in this case, the column means and standard deviations).\n",
    "\n",
    "5) `bake()` function applies the recipe to the dataframe?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a0d88-05c1-46cc-932d-5c5224a1df13",
   "metadata": {},
   "source": [
    "#### 6.3.5 Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087fc496-a5f4-4083-a103-e57630449076",
   "metadata": {},
   "source": [
    "* Rebalance the data by oversampling the rare class.\n",
    "* We will replicate rare observations multiple times in our data set to give them more voting power in the K-nearest neighbour algorithm.\n",
    "* In order to do this, we will add an oversampling step to the earlier `udf_recipe` recipe with the `step_upsample()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f30e83-05d9-4eb1-aebb-19d292ad63e8",
   "metadata": {},
   "source": [
    "##### **<u>Example Code:</u>**\n",
    "\n",
    "```\n",
    "ups_recipe <- recipe(target_col ~ ., data = df) |>          #(1)\n",
    "  step_upsample(target_col, over_ratio = n, df) |>          #(2)\n",
    "  prep()                                                    #(3)\n",
    "\n",
    "upsampled_df <- bake(ups_recipe, df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364ce76-6172-426a-9f44-5ada46454bef",
   "metadata": {},
   "source": [
    "1) `recipe()` creates a Recipe for Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f62ba89-571e-420d-aa04-566af81a27fc",
   "metadata": {},
   "source": [
    "2) `step_upsample()`\n",
    "    * oversamples data points in minority to match those of majority.\n",
    "    * 1st argument selects the `target_col`.\n",
    "    * 2nd argument is a numeric value for the ratio of the majority-to-minority frequencies. (DEFAULT: over_ratio = 1)\n",
    "    * 3rd argument takes in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a1f4fa-9cb3-4bbf-8b7d-8288338d6062",
   "metadata": {},
   "source": [
    "3) `prep()` function finalizes the recipe by using the data to compute anything necessary to run the recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8984846-0591-49bf-830b-4c162c2c3dc1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1423b03-f6e4-4466-9ca1-e2d3e46bdc6d",
   "metadata": {},
   "source": [
    "### 6.4 `workflow()`\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f8c73-93c5-478b-8d2e-2b0f71116288",
   "metadata": {},
   "source": [
    ">* We’re going to use this recipe in a `workflow()` so we don’t need to stress a lot about whether to `prep()` or not. \n",
    ">* If you want to explore what the recipe is doing to your data:\n",
    "    * You can first `prep()` the recipe to estimate the parameters needed for each step\n",
    "    * Then `bake(new_data = NULL)` to pull out the training data with those steps applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65f9444-6977-46d8-b913-53f6ea897a21",
   "metadata": {},
   "source": [
    "##### **<u>Example Code:</u>**\n",
    "```\n",
    "# load the unscaled cancer data and make sure the target Class variable is a factor\n",
    "unscaled_cancer <- read_csv(\"data/unscaled_wdbc.csv\") |> \n",
    "  mutate(Class = as_factor(Class))\n",
    "\n",
    "# create the KNN model\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 7) |> \n",
    "  set_engine(\"kknn\") %>%\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# create the centering / scaling recipe\n",
    "uc_recipe <- recipe(Class ~ Area + Smoothness, data = unscaled_cancer) |> \n",
    "  step_scale(all_predictors()) |> \n",
    "  step_center(all_predictors())\n",
    "\n",
    "knn_fit <- workflow() |> \n",
    "  add_recipe(uc_recipe) |> \n",
    "  add_model(knn_spec) |> \n",
    "  fit(data = unscaled_cancer)\n",
    "\n",
    "knn_fit\n",
    "\n",
    "new_obs <- tibble(Perimeter = 0, Concavity = 3.5)\n",
    "knnPred <- predict(knn_fit, new_obsv)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e26f8fe-99c8-47f0-9259-5b17d78bdf8a",
   "metadata": {},
   "source": [
    "#### 6.4.1 Advantage of using `workflow()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a61acc5-f7aa-4b33-9c92-b2db5fea1ee8",
   "metadata": {},
   "source": [
    "- This is a simple way to chain together multiple data analysis steps without a lot of otherwise necessary code for intermediate steps.\n",
    "- We did not use the select function to extract the relevant variables from the data frame, and instead simply specified the relevant variables to use via the formula `Class ~ Area + Smoothness` (instead of `Class ~ .`) in the recipe.\n",
    "- You will also notice that we did not call `prep()` on the recipe; this is unnecssary when it is placed in a workflow.\n",
    "- We do not include a formula in the fit function. This is again because we included the formula in the recipe, so there is no need to respecify it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755a57be-20b1-430c-9f3d-89179628ac9d",
   "metadata": {},
   "source": [
    "## Chapter 7: Classification II (Evaluation and Tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1cd414-ac3c-423c-a497-d902bdcad396",
   "metadata": {},
   "source": [
    "### 7.1 Common functions we may use in this chapter\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c79824f-6156-48df-9547-c0a0dceec0ca",
   "metadata": {},
   "source": [
    "* `bind_cols(col_object, df)`\n",
    "    * binds the column/vector in argument 1 to dataframe in argument 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02178ac-4e7c-4bc3-91e8-156b32ed72d2",
   "metadata": {},
   "source": [
    "* `rename(df, new_col_name = old_col_name)`\n",
    "    * renames column name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e198a3-9ff6-4c51-bd2f-c6043981e0bb",
   "metadata": {},
   "source": [
    ">**Question**  \n",
    "If we do not have access to the entire population, how do we evaluate our classifier with only the sample we are given?  \n",
    "In other words, how do we EVALUATE our classifier without having to collect NEW observations from the actual source?\n",
    "\n",
    ">**Answer**  \n",
    "The trick is to SPLIT UP the data set into a TRAINING SET and TEST SET, and only show the classifier the TRAINING SET when building the classifier.  \n",
    "Then to evaluate the accuracy of the classifier, we can use it to predict the labels (which we know) in the test set.  \n",
    "If our predictions match the true labels for the observations in the TEST SET very well, then we have some confidence that our classifier might also do a good job of predicting the class labels for NEW observations that we do not have the class labels for.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec8b52e-63e8-4f72-a0bc-0929b77156c8",
   "metadata": {},
   "source": [
    "### 7.2 Measures to assess the classifier\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273c3b1d-1e25-4925-b230-0c35589b94dc",
   "metadata": {},
   "source": [
    "1) **Prediction Accuracy**:\n",
    "$\\frac{\\text{total number of correct predictions}}{\\text{total number of predictions}}$  \n",
    "2) **Precision**  \n",
    "3) **Recall**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfec3de-157c-4216-a81f-c718c24ceab8",
   "metadata": {},
   "source": [
    "### 7.3 Steps to assess the classifier\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac63a75-97be-43df-a60b-3f083afb056b",
   "metadata": {},
   "source": [
    "##### **(1) <u>Create the TRAIN SET and TEST SET</u>**\n",
    "- Training Set should be a 50-100% split of the data  \n",
    "- Test Set should be the remaining 0-50% of data  \n",
    "- You want to trade off between:\n",
    "    - training an accurate model (by using a larger **training** data set)\n",
    "    - getting an accurate evaluation of its performance (by using a larger **test** data set)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597cf9d-d96d-433b-84d1-d6c5db71a5f0",
   "metadata": {},
   "source": [
    "- `initial_split(df, prop = ..., strata = target_column)`\n",
    "    - 2nd argument is the proportion you want for training (e.g. 0.75)\n",
    "    - 3rd argument is the column name of the target variable.\n",
    "    - use `set.seed()` for reproducible results as `initial_split()` randomly samples from df.\n",
    "    - use `training(split_object)` & `testing(split_object)` to assign the training and test sets to respective reference objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0180f5c7-ff80-4f8e-8959-e93a84702a3c",
   "metadata": {},
   "source": [
    "##### **(2) <u>Pre-Process the data</u>**\n",
    "- As we mentioned last chapter, K-NN is sensitive to the scale of the predictors, and so we should perform some preprocessing to standardize them.\n",
    "- We should create the standardization preprocessor **using only the training data**.  \n",
    "(This ensures that our test data does not influence any aspect of our model training)\n",
    "- Once we have created the standardization preprocessor, we can then apply it **separately** to both the **training** and **test** datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17bf50c-bd15-459a-8c9f-7cb145233ac9",
   "metadata": {},
   "source": [
    "##### **(3) <u>Train the Classifier</u>**\n",
    "- Create the K-nearest neighbour classifier with **only** the **training set**.  \n",
    "(Here again you see the set.seed function. In the K-nearest neighbour algorithm, if there is a tie for the majority neighbour class, the winner is randomly selected.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580d2c36-5e14-4faa-ae0c-7745315b407e",
   "metadata": {},
   "source": [
    "##### **(4) <u>Create the labels in the Test set</u>**\n",
    "- Predict the class labels for our **test set** using the `predict()` function\n",
    "- use the `bind_cols()` to add the column of predictions to the original test data creating the predictions dataframe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a7d136-9807-4036-84d5-a5bbb17db1e6",
   "metadata": {},
   "source": [
    "##### **(5) <u>Compute the accuracy</u>**\n",
    "- To assess classifier's accuracy, we use the `metrics()` function.\n",
    "- We can also look at the confusion matrix for the classifier, which shows the table of predicted labels and correct labels, using the `conf_mat()`.\n",
    "- `metrics(df, truth = target_col_name, estimate = .pred_class)`\n",
    "    - 2nd argument takes the name of the the target variable/column\n",
    "    - 3rd argument takes the name of the column with the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6836262d-ce17-497a-8dcc-b7fe7246c928",
   "metadata": {},
   "source": [
    "- `conf_mat(df, truth = Class, estimate = .pred_class)`\n",
    "    - 2nd argument takes the name of the the target variable/column\n",
    "    - 3rd argument takes the name of the column with the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1280ec6a-ff95-4176-8ac3-efe685d2acaf",
   "metadata": {},
   "source": [
    "#### **Sample Code:**\n",
    "```\n",
    "##(1)##\n",
    "set.seed(1)\n",
    "cancer_split <- initial_split(cancer, prop = 0.75, strata = Class)\n",
    "cancer_train <- training(cancer_split)\n",
    "cancer_test <- testing(cancer_split)\n",
    "\n",
    "##(2)##\n",
    "cancer_recipe <- recipe(Class ~ Smoothness + Concavity, data = cancer_train) |>\n",
    "  step_scale(all_predictors()) |>\n",
    "  step_center(all_predictors())\n",
    "\n",
    "##(3)##\n",
    "set.seed(1)\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 3) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "knn_fit <- workflow() |>\n",
    "  add_recipe(cancer_recipe) |>\n",
    "  add_model(knn_spec) |>\n",
    "  fit(data = cancer_train)\n",
    "\n",
    "knn_fit\n",
    "\n",
    "##(4)##\n",
    "cancer_test_predictions <- predict(knn_fit, cancer_test) |>\n",
    "  bind_cols(cancer_test)\n",
    "cancer_test_predictions\n",
    "\n",
    "##(5)##\n",
    "cancer_test_predictions |>\n",
    "  metrics(truth = Class, estimate = .pred_class)\n",
    "\n",
    "cancer_test_predictions |>\n",
    "  conf_mat(truth = Class, estimate = .pred_class)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94e0409-2c8a-48b4-8a18-24c0c109f7a9",
   "metadata": {},
   "source": [
    "### 7.4 Tuning the model\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147be89c-0cf8-40c7-b578-5544fa3fd52a",
   "metadata": {},
   "source": [
    "- Predictive models in statistics and machine learning have parameters that you have to pick.\n",
    "- For example, in the K-nearest neighbour classification algorithm we have had to pick the number of neighbours K for the class vote.\n",
    "- Making the most optimal selection is called **Tuning** the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd58ff9-e2c4-43a4-9306-a2afe693fb52",
   "metadata": {},
   "source": [
    ">**Question**  \n",
    "How do we tune the model?\n",
    "\n",
    ">**Answer**\n",
    ">1) Split our **Training data** further into **two** subsets, called the **Training (sub)set** and **Validation set**.  \n",
    ">2) Use the **Training (sub)set** for building the classifier, and the **Validation set** for evaluating it!  \n",
    ">3) Then we will try different values of the parameter $K$ and pick the one that yields the highest accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e61764-65a8-4e43-96ef-380177347ef4",
   "metadata": {},
   "source": [
    "#### 7.4.1 Cross Validation Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e48f467-8ae1-435c-9998-efdced08f409",
   "metadata": {},
   "source": [
    "- Instead of randomly splitting the data, we want each observation in the data set to be used in a validation set only a single time.\n",
    "- The name for this strategy is called cross-validation.\n",
    "- In cross-validation, we split our overall **Training data** into $V$ evenly-sized chunks/folds\n",
    "- Then iteratively use 1 chunk as the **Validation set** and combine the remaining $V−1$ chunks as the **Training (sub)set**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49fd1f1-9046-43b0-ad64-aca822aff712",
   "metadata": {},
   "source": [
    "$$\\text{Cross-validation accuracy} = \\frac{\\sum{\\text{accuracy of n folds}}}{\\text{number of folds}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54eb613-6aed-40f4-a5da-8e4e3324d177",
   "metadata": {},
   "source": [
    "#### 7.4.2 Use the following functions to perform $V$-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86fda32-42fd-4d10-8b1d-f3e8709e2d3e",
   "metadata": {},
   "source": [
    "- `vfold_cv(training_dataframe, v = ..., strata = target_column)`\n",
    "    - This function splits our training data into $V$ folds automatically\n",
    "    - This is to be done after data has been split onto **Training** and **Test** sets.\n",
    "    - Cross-validation uses a random process to select how to partition the training data therefore use `set.seed()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b4f4c4-f9de-470c-bf7e-e7f32616a10a",
   "metadata": {},
   "source": [
    "- `fit_resamples(..., resamples = df_vfold)`\n",
    "    - it is used instead of `fit()` function when doing cross-validation **for only specified neighbours**.\n",
    "    - This runs cross-validation on each train/validation split.\n",
    "    - first argument is the `worklfow()` function which is piped in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9149af9e-1189-4cb5-829e-b17b3cd492da",
   "metadata": {},
   "source": [
    "- `tune_grid(..., resamples = df_vfold, grid = n)`\n",
    "    - it is used instead of `fit_resamples()` function when doing cross-validation for $n$ neighbours.\n",
    "    - fits the model for each value in a range of parameter values\n",
    "    - third argument specifies that the tuning should try at most $n$ values of the number of neighbours $K$ when tuning.\n",
    "    - first argument is the `workflow()` which is piped in.\n",
    "    - We set the seed prior to tuning to ensure results are reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a738a-633e-4181-98ed-f27049d701e7",
   "metadata": {},
   "source": [
    "- `collect_metrics(...)`\n",
    "    - Used instead of `metrics()` function when doing cross-validation.\n",
    "    - Used to aggregate the mean and standard error of the classifier’s validation accuracy across the folds.\n",
    "    - argument is the `workflow()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87be48b9-dee1-453c-907d-7cd5a2a0098f",
   "metadata": {},
   "source": [
    "- `tune()`\n",
    "    - Each parameter in the model to be tuned should be specified as `tune()` in the model specification rather than given a particular value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657bdde5-ff1d-4a25-9e32-01405e75595b",
   "metadata": {},
   "source": [
    "#### 7.4.3 Code required to perform $V$-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882b6929-1456-4747-9041-c7770fddbfb4",
   "metadata": {},
   "source": [
    "```\n",
    "set.seed(1)\n",
    "\n",
    "cancer_vfold <- vfold_cv(cancer_train, v = 10, strata = Class)\n",
    "\n",
    "cancer_recipe <- recipe(Class ~ Smoothness + Concavity, data = cancer_train) |>\n",
    "  step_scale(all_predictors()) |>\n",
    "  step_center(all_predictors())\n",
    "\n",
    "\n",
    "# Specify the model for v-fold cross validation\n",
    "# neighbors = tune() is used when we want to test the accuracies for a range of different parameter values.\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "set.seed(1)\n",
    "knn_results <- workflow() |>\n",
    "  add_recipe(cancer_recipe) |>\n",
    "  add_model(knn_spec) |>\n",
    "  tune_grid(resamples = cancer_vfold, grid = 10) |>\n",
    "  collect_metrics()\n",
    "knn_results\n",
    "\n",
    "accuracies <- knn_results |>\n",
    "  filter(.metric == \"accuracy\")\n",
    "\n",
    "---------------------------------------------------------------------------------------------\n",
    "Now check for most optimal accuracy (usually the highest and most stable one) by plotting them\n",
    "---------------------------------------------------------------------------------------------\n",
    "\n",
    "# Plot of k values against their respective accuracies\n",
    "cross_val_plot <- accuracies |> \n",
    "    ggplot(aes(x = neighbors, y = mean)) +\n",
    "    geom_point() +\n",
    "    geom_line() +\n",
    "    labs(x = \"Neighbors\", y = \"Accuracy Estimate\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4fc0c6-7b42-43ca-9158-abc82495fe49",
   "metadata": {},
   "source": [
    "#### 7.4.4 Notes about $V$-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d6fed-a0bb-41e0-a211-f28493e4f0b1",
   "metadata": {},
   "source": [
    "- When you do cross-validation, you need to consider the size of the data, the speed of the algorithm (e.g., K-nearest neighbour) and the speed of your computer. \n",
    "- In practice, this is a trial and error process, but typically $V$ is chosen to be either 5 or 10.\n",
    "- The more the folds, the lesser the standard error but the more expensive the computation.\n",
    "- How good or not the prediction accuracy is depends entirely on the downstream application of the data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e3d8fe-f695-4bab-9134-0365eb9d4421",
   "metadata": {},
   "source": [
    ">**Question**  \n",
    "How do you decide which parameter value is the \"Best\"?\n",
    "\n",
    ">**Answer**  \n",
    "Generally, when selecting $K$ (and other parameters for other predictive models), we are looking for a value where:\n",
    ">1) we get roughly **optimal accuracy**, which means that changing the value to a nearby one (e.g. from K=7 to 6 or 8) does not decrease the accuracy too much therefore making our choice reliable in the presence of uncertainty\n",
    ">2) the cost of training the model is not prohibitive (e.g., in our situation, if $K$ is too large, predicting becomes expensive!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fcb78b-d57e-40b5-876e-392e57ea7437",
   "metadata": {},
   "source": [
    "### 7.5 Underfitting and Overfitting\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3147ec5d-1189-4474-8071-8f7a2a349df1",
   "metadata": {},
   "source": [
    "<u>**Under-fitting:**</u>  \n",
    "As we increase the number of neighbours, more and more of the training observations (and those that are farther and farther away from the point)\n",
    "get a “say” in what the class of a new observation is. This causes a sort of “averaging effect” to take place, making the boundary between where\n",
    "our classifier would predict a tumour to be malignant versus benign to smooth out and become simpler.\n",
    "\n",
    "In general, if the model isn’t influenced enough by the training data, it is said to underfit the data.\n",
    "\n",
    "\n",
    "<u>**Over-fitting:**</u>  \n",
    "In contrast, when we decrease the number of neighbours, each individual data point has a stronger and stronger vote regarding nearby points. \n",
    "Since the data themselves are noisy, this causes a more “jagged” boundary corresponding to a less simple model.\n",
    "This is just as problematic as the large $K$ case, because the classifier becomes unreliable on new data:\n",
    "if we had a different training set, the predictions would be completely different.\n",
    "\n",
    "In general, if the model is influenced too much by the training data, it is said to overfit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf9373-f19d-4502-9974-11fcc2be0c64",
   "metadata": {},
   "source": [
    "### 7.6 Shuffling and Stratification\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f63ded-82cb-46c9-a510-06bdf3abb7fe",
   "metadata": {},
   "source": [
    "<u>**Shuffling:**</u>  \n",
    "When we split the data into train, test, and validation sets, we make the assumption that there is no order to our originally collected data set. However, if we think that there might be some order to the original data set, then we can randomly shuffle the data before splitting it. The tidymodels function `initial_split()` and `vfold_cv()` functions do this for us.\n",
    "\n",
    "\n",
    "<u>**Stratification:**</u>  \n",
    "If the data are imbalanced, we also need to be extra careful about splitting the data to ensure that enough of each class ends up in each of the train, validation, and test partitions. The strata argument in the `initial_split()` and `vfold_cv()` functions handles this for us too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc68520f-79d8-4a3f-955a-1855eccf9b72",
   "metadata": {},
   "source": [
    "### 7.7 Advantages and Disadvantages of K-NN Classification\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50728ee-8581-4149-ad6e-21b83f329995",
   "metadata": {},
   "source": [
    "<u>**Advantages:**</u>  \n",
    "* Simple and easy to understand\n",
    "* No assumptions about what the data must look like\n",
    "* Works easily for binary (two-class) and multi-class (> 2 classes) classification problems\n",
    "\n",
    "\n",
    "<u>**Disadvantages:**</u>  \n",
    "* As data gets bigger and bigger, K-nearest neighbour gets slower and slower, quite quickly\n",
    "* Does not perform well with a large number of predictors\n",
    "* Does not perform well when classes are imbalanced (when many more observations are in one of the classes compared to the others)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00bc895-7253-4b85-9d75-ba55f129f514",
   "metadata": {},
   "source": [
    "### 7.8 The overall workflow for performing K-nearest neighbour classification using tidymodels is as follows\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa06fc-6c2e-444b-8209-38bb85d15194",
   "metadata": {},
   "source": [
    "0) First read the data into R and apply `as_factor()` on the column/variable you want to choose as your target variable.  \n",
    "1) Use the `initial_split()` function to split the data into a **training** and **test** set. Set the strata argument to the target variable. Put the test set aside for now.  \n",
    "2) Use the `vfold_cv()` function to split up the **training data** for cross validation.  \n",
    "3) Create a **recipe** that specifies the **target** and **predictor variables**, as well as **preprocessing steps** for all variables. Pass the **training data** as the data argument of the **recipe**.  \n",
    "4) Create a nearest_neighbors `model specification`, with `neighbors = tune()`.  \n",
    "5) Add the `recipe` and `model specification` to a `workflow()`, and use the `tune_grid()` function on the train/validation splits to estimate the classifier accuracy for a range of $K$ values.  \n",
    "6) Pick a value of $K$ that yields a high accuracy estimate that does not change much if you change $K$ to a nearby value. In the K-nearest neighbours classification algorithm, we choose the label/class for a new observation by taking the mode (value that appears most often, i.e., the majority vote) label/class of the K nearest neighbours.  \n",
    "7) Make a new model specification for the best parameter value, and re-train the classifier using the `fit()` function.  \n",
    "8) Evaluate the estimated accuracy of the classifier on the test set using the predict function.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066b0296-853c-452d-bebc-a61a046956da",
   "metadata": {},
   "source": [
    "##### <u>**Example Code:**</u>\n",
    "```\n",
    "##(0)##\n",
    "unscaled_cancer <- read_csv(\"data/unscaled_wdbc.csv\") |> \n",
    "  mutate(Class = as_factor(Class))\n",
    "\n",
    "##(1)##\n",
    "set.seed(1)\n",
    "cancer_split <- initial_split(cancer, prop = 0.75, strata = Class)\n",
    "cancer_train <- training(cancer_split)\n",
    "cancer_test <- testing(cancer_split)\n",
    "\n",
    "##(2)##\n",
    "set.seed(1)\n",
    "cancer_vfold <- vfold_cv(cancer_train, v = 10, strata = Class)\n",
    "\n",
    "##(3)##\n",
    "cancer_recipe <- recipe(Class ~ Smoothness + Concavity, data = cancer_train) |>\n",
    "  step_scale(all_predictors()) |>\n",
    "  step_center(all_predictors())\n",
    "\n",
    "##(4)##\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "##(5)##\n",
    "set.seed(1)\n",
    "knn_results <- workflow() |>\n",
    "  add_recipe(cancer_recipe) |>\n",
    "  add_model(knn_spec) |>\n",
    "  tune_grid(resamples = cancer_vfold, grid = 10) |>\n",
    "  collect_metrics() |>\n",
    "  filter(.metric == \"accuracy\")\n",
    "\n",
    "##(6)##\n",
    "# Plot k values against their respective accuracies and choose optimal k value\n",
    "cross_val_plot <- knn_results |> \n",
    "    ggplot(aes(x = neighbors, y = mean)) +\n",
    "    geom_point() +\n",
    "    geom_line() +\n",
    "    labs(x = \"Neighbors\", y = \"Accuracy Estimate\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "\n",
    "##(7)##\n",
    "knn_best_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 5) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "cancer_fit <- workflow() |>\n",
    "  add_recipe(cancer_recipe) |>\n",
    "  add_model(knn_best_spec) |>\n",
    "  fit(data = cancer_train) |>\n",
    "  collect_metrics()\n",
    "  \n",
    "##(8)##\n",
    "# Get the prediction column\n",
    "cancer_predictions <- predict(cancer_fit, cancer_test) |> \n",
    "    bind_cols(cancer_test)\n",
    "\n",
    "# Compare the accuracy of predictions to the true values in the test set\n",
    "cancer_acc <- cancer_predictions |> \n",
    "    metrics(truth = Classes, estimate = .pred_class) |> \n",
    "    select(.metric, .estimate) |> \n",
    "    head(1)\n",
    "\n",
    "# Compare the predictions to the true values in a confusion matrix\n",
    "cancer_cm <- cancer_predictions |> \n",
    "    conf_mat(truth = Classes, estimate = .pred_class)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5dbf45-686d-4e00-8e00-6a885d29556c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf9019-4735-4dfe-bd91-3232d45a2af5",
   "metadata": {},
   "source": [
    "## Chapter 8: Regression I (K-NN Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1044e756-d58d-4fda-9c5e-f0b04d791560",
   "metadata": {},
   "source": [
    "### 8.1 Introduction to K-NN regression\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466d6de9-332b-41ac-a9c1-09ab0986cf25",
   "metadata": {},
   "source": [
    "* Regression, like classification, is a predictive problem setting where we want to use past information to predict future observations.\n",
    "* The goal is to predict numerical values instead of class labels.\n",
    "* To predict a value of $Y$ for a new observation using k-nn regression, we identify the k-nearest neighbours and then assign it the mean of the k-nearest neighbours as the predicted value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38f5e0b-2586-4397-9c79-32a2b504932c",
   "metadata": {},
   "source": [
    "#### 8.1.1 Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6932234-e073-411d-b100-d9f2e287197b",
   "metadata": {},
   "source": [
    "* Root Mean Square Error (RMSE) is the standard deviation of the residuals (prediction errors). Residuals are a measure of how far from the regression line data points are; RMSE is a measure of how spread out these residuals are. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6fa032-e26c-41b4-8454-b15d5226b655",
   "metadata": {},
   "source": [
    "$$\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}{\\left(\\hat{y_i}-{y_i}\\right)^2}}$$\n",
    "\n",
    "<p><center>\n",
    "  <img src = \"https://miro.medium.com/max/611/1*jopCO2kMEI84s6fiGKdXqg.png\" width = \"500\"/>\n",
    "</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b33787-ee40-4ca9-90de-5b64d427b461",
   "metadata": {},
   "source": [
    "#### 8.1.2 RMSE vs RMSPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2674bf1-1747-4c2b-8fbe-b8108514ba2b",
   "metadata": {},
   "source": [
    "* When predicting and evaluating prediction quality on the **training data**, we say $\\text{RMSE}$.\n",
    "* By contrast, when predicting and evaluating prediction quality on the **testing data** or **validation data**, we say $\\text{RMSPE}$.\n",
    "> $\\text{RMSE}$ is a measure of goodness of fit.  \n",
    "$\\text{RMSE}$ measures how well the model predicts on data it was trained with.  \n",
    "$\\text{RMSPE}$ is a measure of prediction quality.  \n",
    "$\\text{RMSPE}$ measures how well the model predicts on data it was not trained with.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4957dea7-87a9-4e08-a74b-9fceb6b26c62",
   "metadata": {},
   "source": [
    "### 8.2 Performing Regression with K-NN Algorithm\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ce4ee9-8cca-420b-b9a7-5defb874d13d",
   "metadata": {},
   "source": [
    ">* We will create a model specification for K-nearest neighbours regression, as well as a recipe for preprocessing our data.  \n",
    ">* ***Note:*** We use `set_mode(\"regression\")` which essentially tells tidymodels that we need to use different metrics i.e. $\\text{RMSPE}$ (not accuracy) for tuning and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7365a2e-803b-443d-8f80-68fcb618227c",
   "metadata": {},
   "source": [
    "##### <u>**Example Code:**</u>\n",
    "```\n",
    "marathon_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>% \n",
    "      set_engine(\"kknn\") %>%\n",
    "      set_mode(\"regression\") \n",
    "\n",
    "marathon_recipe <- recipe(time_hrs ~ max, data = marathon_training) %>%\n",
    "      step_scale(all_predictors()) %>%\n",
    "      step_center(all_predictors())\n",
    "\n",
    "marathon_vfold <- vfold_cv(marathon_training, v = 5, strata = time_hrs)\n",
    "\n",
    "gridvals <- tibble(neighbors = seq(1, 200))\n",
    "\n",
    "marathon_results <- workflow() %>% \n",
    "    add_recipe(marathon_recipe) %>% \n",
    "    add_model(marathon_spec) %>%\n",
    "    tune_grid(resamples = marathon_vfold, grid = gridvals) %>% \n",
    "    collect_metrics()\n",
    "\n",
    "# show all the results\n",
    "marathon_results\n",
    "\n",
    "----------------------------------\n",
    "\n",
    "# show only the row of minimum RMSPE\n",
    "marathon_min <- marathon_results %>%\n",
    "   filter(.metric == \"rmse\") %>%\n",
    "   arrange(mean) %>% \n",
    "   head(1)\n",
    "\n",
    "marathon_min\n",
    "\n",
    "----------------------------------\n",
    "\n",
    "k_min <- marathon_min %>%\n",
    "         pull(neighbors)\n",
    "\n",
    "marathon_best_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = k_min) %>%\n",
    "         set_engine(\"kknn\") %>%\n",
    "         set_mode(\"regression\")\n",
    "\n",
    "marathon_best_fit <- workflow() %>%\n",
    "         add_recipe(marathon_recipe) %>%\n",
    "         add_model(marathon_best_spec) %>%\n",
    "         fit(data = marathon_training)\n",
    "\n",
    "marathon_summary <- marathon_best_fit %>%\n",
    "          predict(marathon_testing) %>%\n",
    "          bind_cols(marathon_testing) %>%\n",
    "          metrics(truth = time_hrs, estimate = .pred)\n",
    "\n",
    "marathon_summary\n",
    "\n",
    "------------------------------------------------------------------------------------\n",
    "[Plotting Regression line with K-NN Algorithm on training data]\n",
    "------------------------------------------------------------------------------------\n",
    "\n",
    "marathon_preds <- marathon_best_fit %>%\n",
    "  predict(marathon_training) %>%\n",
    "  bind_cols(marathon_training)\n",
    "\n",
    "marathon_plot <- ggplot(marathon_preds, aes(x = max, y = time_hrs)) +\n",
    "  geom_point(alpha = 0.4) +\n",
    "  labs(x = \"Maximum Distance Ran per \\n Week During Training (mi)\",\n",
    "       y = \"Race Time (hours)\") +\n",
    "  geom_line(data = marathon_preds, aes(x = max, y = .pred), color = \"blue\") +\n",
    "  ggtitle(paste0(\"K = \", k_min)) +\n",
    "  theme(text = element_text(size = 20))\n",
    "\n",
    "marathon_plot\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efa3a7d-0de3-4faf-8cdf-96be817c9a54",
   "metadata": {},
   "source": [
    "### 8.3 Stength and Limitations of K-NN Regression\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffe14d4-763b-47c2-af6c-ccab35f275f0",
   "metadata": {},
   "source": [
    "<u>**Strengths:**</u>  \n",
    "1) Simple and easy to understand  \n",
    "2) No assumptions about what the data must look like  \n",
    "3) Works well with non-linear relationships (i.e., if the relationship is not a straight line)  \n",
    "\n",
    "\n",
    "<u>**Limitations:**</u>  \n",
    "1) As data gets bigger and bigger, K-NN gets slower and slower, quite quickly 2. Does not perform well with a large number of predictors unless the size of the training set is exponentially larger.  \n",
    "2) Does not predict well beyond the range of values input in your training data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ab388f-7f89-4fb6-b42a-fb4059436533",
   "metadata": {},
   "source": [
    "### 8.4 Overfitting vs Underfitting\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba2821-f43b-4639-9126-b5cbe673ef34",
   "metadata": {},
   "source": [
    "<u>**Overfitting:**</u>  \n",
    "Creates high variance and low bias.  \n",
    "It has high variance because the flexible blue line follows the training observations very closely, \n",
    "and if we were to change any one of the training observation data points we would change the flexible blue line quite a lot. \n",
    "This means that the blue line matches the data we happen to have in this training data set, however, \n",
    "if we were to collect another training data set from the Sacramento real estate market it likely wouldn’t match those observations as well.\n",
    "\n",
    "\n",
    "<u>**Underfitting:**</u>  \n",
    "Creates low variance and high bias as the blue line is extremely smooth, and almost flat.  \n",
    "This happens because our predicted values for a given x value (here home size), depend on many many (450) neighbouring observations.  \n",
    "A model like this has low variance and high bias (intuitively, it provides very reliable, but generally very inaccurate predictions).  \n",
    "It has low variance because the smooth, inflexible blue line does not follow the training observations very closely, and if we were to change any one of the training observation data points it really wouldn’t affect the shape of the smooth blue line at all.  \n",
    "This means that although the blue line matches does not match the data we happen to have in this particular training data set perfectly, if we were to collect another training data set from the Sacramento real estate market it likely would match those observations equally as well as it matches those in this training data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f0d4b-ef12-439e-a141-ae58f9e21401",
   "metadata": {},
   "source": [
    "## Chapter 9: Regression II (Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5b619d-139b-46d5-82d6-4ed2c95fc5e5",
   "metadata": {},
   "source": [
    "### 9.0 Important Packages for Chapter 9\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45befcb-3e5b-4a5d-9d91-7bb360803164",
   "metadata": {},
   "source": [
    "* `tidymodels`\n",
    "    * We can perform simple linear regression in R using tidymodels in a very similar manner to how we performed KNN regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb742780-775a-401e-b1b8-052e4bde7b18",
   "metadata": {},
   "source": [
    "### 9.1 Introduction to Linear Regression\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13e87c0-f327-4227-9fbc-627820655ced",
   "metadata": {},
   "source": [
    "- In KNN regression, we look at the K nearest neighbours and average over their values for a prediction. \n",
    "- In simple linear regression, we create a straight line of best fit through the training data and then “look up” the prediction using the line.\n",
    "  Therefore using the data to find the line of best fit is equivalent to finding coefficients $\\beta_{0}$ and $\\beta_{1}$ that parametrize (correspond to) the line of best fit. \n",
    "- Simple linear regression chooses the straight line of best fit by choosing the line that minimizes the average squared vertical distance between itself and each of the observed data points in the training data.\n",
    "- To assess the predictive accuracy of a simple linear regression model, we use $\\text{RMSPE}$, the same measure of predictive performance we used with KNN regression.\n",
    "- An additional difference that you will notice below is that we do not standardize (i.e., scale and center) our predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e10220c-7272-4376-84c5-2431541ceab0",
   "metadata": {},
   "source": [
    "### 9.2 Performing Multivaraite Linear Regression\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f03ff88-31d9-463b-bbb7-742396c09fb0",
   "metadata": {},
   "source": [
    "##### <u>**Example Code:**</u>\n",
    "```\n",
    "set.seed(1234)\n",
    "sacramento_split <- initial_split(sacramento, prop = 0.6, strata = price)\n",
    "sacramento_training <- training(sacramento_split)\n",
    "sacramento_testing <- testing(sacramento_split)\n",
    "\n",
    "\n",
    "lm_spec <- linear_reg() %>%\n",
    "  set_engine(\"lm\") %>%\n",
    "  set_mode(\"regression\")\n",
    "\n",
    "mlm_recipe <- recipe(price ~ sqft + beds, data = sacramento_training)\n",
    "\n",
    "mlm_fit <- workflow() %>%\n",
    "  add_recipe(mlm_recipe) %>%\n",
    "  add_model(lm_spec) %>%\n",
    "  fit(data = sacramento_training)\n",
    "mlm_fit\n",
    "\n",
    "\n",
    "lm_mult_test_results <- mlm_fit %>%\n",
    "  predict(sacramento_testing) %>%\n",
    "  bind_cols(sacramento_testing) %>%\n",
    "  metrics(truth = price, estimate = .pred)\n",
    "lm_mult_test_results\n",
    "\n",
    "\n",
    "# Take this step if you want the RMSPE value.\n",
    "lm_rmspe <- lm_test_results %>%\n",
    "         filter(.metric == \"rmse\") %>%\n",
    "         select(.estimate) %>%\n",
    "         pull()\n",
    "\n",
    "\n",
    "------------------------------------------------------------------------------------\n",
    "Visualizing the Simple Regression model\n",
    "------------------------------------------------------------------------------------\n",
    "\n",
    "- To visualize the simple linear regression model, we can plot the predicted house sale price across all possible house sizes we might encounter superimposed on a scatter plot of the original housing price data.\n",
    "- There is a plotting function in the tidyverse, geom_smooth, that allows us to add a layer on our plot with the simple linear regression predicted line of best fit.\n",
    "\n",
    "\n",
    "lm_plot_final <- ggplot(sacramento_training, aes(x = sqft, y = price)) +\n",
    "  geom_point(alpha = 0.4) +\n",
    "  xlab(\"House size (square feet)\") +\n",
    "  ylab(\"Price (USD)\") +\n",
    "  scale_y_continuous(labels = dollar_format()) +\n",
    "  geom_smooth(method = \"lm\", se = FALSE)\n",
    "lm_plot_final\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b92a3-2bfe-4404-ac29-1b6a05dde416",
   "metadata": {},
   "source": [
    "#### 9.2.1 Extracting Coefficients from Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f265c4-6f8d-428c-871d-69813c3ecd45",
   "metadata": {},
   "source": [
    "* We can extract the coefficients from our model by accessing the fit object that is output by the fit function.\n",
    "* We first have to extract it from the workflow using the `pull_workflow_fit()` function.\n",
    "* Then apply the tidy function to convert the result into a data frame:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911016d1-ef9c-4f58-9abc-ccce4ce70897",
   "metadata": {},
   "source": [
    "##### <u>**Example Code:**</u>\n",
    "```\n",
    "coeffs <- lm_fit %>%\n",
    "             pull_workflow_fit() %>%\n",
    "             tidy()\n",
    "coeffs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd07d26-4080-4623-b9fd-23229d6bceb8",
   "metadata": {},
   "source": [
    "### 9.3 Comparison of Linear Regression vs KNN Regression\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41269f5f-6352-466e-ae7a-83f30456139d",
   "metadata": {},
   "source": [
    "<u>**Advantages of Linear Regression over KNN-regression:**</u>  \n",
    "1) KNN regression does **NOT** predict well beyond the range of the predictors in the training data. Linear regression can be used to address this problem.\n",
    "2) In KNN regression, the method gets significantly slower as the training dataset grows. Linear regression can be used to address this problem.\n",
    "3) In linear regression, standardization does not affect the fit (it does affect the coefficients in the equation, though!)\n",
    "4) A straight line can be defined by two numbers, the vertical intercept and the slope. The intercept tells us what the prediction is when all of the predictors are equal to 0; and the slope tells us what unit increase in the target/response variable we predict given a unit increase in the predictor variable. KNN regression, as simple as it is to implement and understand, has no such interpretability from its wiggly line.\n",
    "\n",
    "<u>**Disadvantages of Linear Regression when compared to KNN-regression:**</u>  \n",
    "1) When the relationship between the target and the predictor is not linear, but instead some other shape (e.g. curved or oscillating).  In these cases the prediction model from a simple linear regression will underfit (have high bias), meaning that model/predicted values does not match the actual observed values very well. Such a model would probably have a quite high $\\text{RMSE}$ when assessing model goodness of fit on the training data and a quite high $\\text{RMSPE}$ when assessing model prediction quality on a test data set.\n",
    "\n",
    "On such a data set, KNN regression may fare better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdb171a-d2e8-4b99-94aa-5505fd9a30f6",
   "metadata": {},
   "source": [
    "### 9.3 Extrapolation\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8d8aa1-53e2-49ba-93e7-6cb4eb710839",
   "metadata": {},
   "source": [
    "<u>**Extrapolation problems**</u>  \n",
    "* Predicting outside the range of the observed data is known as extrapolation; KNN and linear models behave quite differently when extrapolating.  \n",
    "* Depending on the application, the flat or constant slope trend may make more sense.  \n",
    "* For example, if our housing data were slightly different, the linear model may have actually predicted a negative price for a small houses (if the intercept $\\beta_{0}$ was negative), which obviously does not match reality.  \n",
    "* On the other hand, the trend of increasing house size corresponding to increasing house price probably continues for large houses, so the “flat” extrapolation of KNN likely does not match reality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07ba901-ec62-4f19-8772-c7b2efab0fcd",
   "metadata": {},
   "source": [
    "### 9.4 Tuning to find out which set of predictors best fit the model\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f5e0f7-d634-45ff-bfa5-ece04ac4950f",
   "metadata": {},
   "source": [
    "* If we are trying out many different sets of predictors for multivariate linear and KNN regression, we must perform this comparison using cross-validation on only our training data.  \n",
    "* But if we have already decided on a small number (e.g., 2 or 3) of tuned candidate models and we want to make a final comparison, we can do so by comparing the prediction error of the methods on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041e6552-2987-4554-ab05-1a03fad11cc7",
   "metadata": {},
   "source": [
    "### 9.4 Problems of Linear Regression\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4131fb5a-20d4-4a11-814a-94e582e98bfa",
   "metadata": {},
   "source": [
    "1) **Outliers**  \n",
    "The problem with outliers is that they can have too much influence on the line of best fit.\n",
    "\n",
    "2) **Collinearity problem in Multivariate linear regression**  \n",
    "If collinearity between predictors are very high, then the plane of best fit will have regression coefficients that are very sensitive to the exact values in the data.  \n",
    "We can design new predictors (by centering them) to tackle this problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5accd1e-4626-4c62-a412-dc9e8791755d",
   "metadata": {},
   "source": [
    "### 9.5 Designing New Predictors\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8e9fee-f44a-4219-b36c-ca0001ca89a5",
   "metadata": {},
   "source": [
    "* Instead of trying to predict the response y using a linear regression on x, we might have some scientific background about our problem to suggest that y should be a cubic function of x. So before performing regression, we might create a new predictor variable z using the mutate function:\n",
    "\n",
    "* The process of transforming predictors (and potentially combining multiple predictors in the process) is known as **Feature Engineering**.\n",
    "```\n",
    "df <- df %>%\n",
    "        mutate(z = x^3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9cce01-381c-4490-9ed2-e557e05597f5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15af99f5-4a4b-47d5-8219-69a1b8da7d4c",
   "metadata": {},
   "source": [
    "# Goodluck with Quiz 2!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
